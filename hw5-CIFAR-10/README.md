# ğŸ“• Introduction
è¿™æ˜¯æœ¬å­¦æœŸæ·±åº¦å­¦ä¹ æœ€åä¸€æ¬¡ç¼–ç¨‹ä½œä¸šï¼Œä½¿ç”¨pytorchå®ç°CIFAR-10åˆ†ç±»ã€‚ä½¿ç”¨æ®‹ä½™ç½‘ç»œ(residual networks)é€šè¿‡ä¿ç•™è¾“å…¥çš„ç‰¹å¾è¾¾åˆ°å³ä½¿æ˜¯å¾ˆæ·±çš„layerå‡†ç¡®ç‡ä¹Ÿä¸ä¼šé™ä½çš„æ•ˆæœã€‚  
æœ¬æ¬¡æ¨¡å‹çš„architectureæ˜¯åŸºäº"Identity Mappings in Deep Residual Networks"å®ç°  
* link: https://arxiv.org/pdf/1603.05027.pdf  

æ¥ä¸‹æ¥å¯¹æœ¬ç¥ç»ç½‘ç»œè¿›è¡Œç®€å•çš„è¯´æ˜ï¼Œå¦‚æœæƒ³è¯¦ç»†äº†è§£å¦‚æ¯ä¸ªstageå’Œblockçš„æ„é€ å¯ä»¥å‚è€ƒPA1.pdfæ–‡ä»¶



## ğŸ¤” How To Run

1. Install the [requirement](https://raw.githubusercontent.com/Lin-CX/deep-learning/main/requirements_dl.txt) packages of this project.
2. `git clone https://github.com/Lin-CX/deep-learning/tree/main/hw5-CIFAR-10`

3. `python3 CIFAR-10.py`



## Some Screenshots

### ğŸˆ Architecture of entire network
* inputå…ˆç»è¿‡3x3 convå±‚ï¼Œå†ç»è¿‡å››ä¸ªstagesï¼Œæœ€åavg poolingåé€šè¿‡full connectionå¾—åˆ°ç»“æœã€‚  
<div  align="center"><kbd>    
    <img src="./netword_archi.png" alt="netword architecture" align=center width="60%" />
</kbd></div><br>  
  

* Stage 1 architecture:  
<div  align="center"><kbd>    
    <img src="./stage1.png" alt="stage architecture" align=center width="70%" />
</kbd></div><br>  
  

* Stage 2:  
<div  align="center"><kbd>    
    <img src="./stage2.png" alt="stage architecture" align=center width="70%" />
</kbd></div><br>  
  

* Stage 3 and stage 4:
<div  align="center"><kbd>    
    <img src="./stage3&4.png" alt="stage architecture" align=center width="70%" />
</kbd></div><br>  
  

### ğŸˆ Running:
* é¦–å…ˆæ£€æµ‹èƒ½å¦ä½¿ç”¨GPUåŠ é€Ÿï¼Œå¦‚æœä¸èƒ½åˆ™è‡ªåŠ¨ä½¿ç”¨CPUï¼Œç„¶åæ‰“å°å½“å‰è®¾å¤‡
* ä¸‹è½½å­¦ä¹ èµ„æ–™
* æ¯2000ä¸ªmini-batchesè¾“å‡ºä¸€æ¬¡ä¿¡æ¯ï¼Œæ ¼å¼å¦‚ä¸‹ã€‚å†…å®¹æœ‰èŠ±è´¹æ—¶é—´ï¼Œå½“å‰epoch, batchæ•°ï¼Œloss
    * elapsed: ...  sec
    [epoch, mini-batches] loss: ...

<div  align="center"><kbd>    
    <img src="./runing.png" alt="runing" align=center width="70%" />
</kbd></div><br>  

### ğŸˆ Result when each stage has only 2 blocks  (the accuracy can be increased by adjusting the number of blocks)  
<div  align="center"><kbd>    
    <img src="./result.png" alt="result architecture" align=center width="70%" />
</kbd></div><br>  

## ğŸˆ How to modify the number of block
ç”±äºåªæ˜¯ä½œä¸šæ‰€ä»¥æ¯ä¸ªstageåªæœ‰ä¸¤ä¸ªblock:  
```python
# define network
net = IdentityResNet(nblk_stage1=2, nblk_stage2=2,
                     nblk_stage3=2, nblk_stage4=2)
```
å¦‚æœæƒ³è°ƒæ•´blockæ•°ä»¥æé«˜å‡†ç¡®åº¦åœ¨ä¸Šæ–¹ä»£ç ä¸­ä¿®æ”¹æ•°å­—å³å¯

* Result of changed the block number of netword and data augmentation as below, accuracy increased 8%


```python
# using RandomHorizontalFlip and RandomCrop function to data augmentation
transform = transforms.Compose([transforms.RandomHorizontalFlip(),
                                transforms.RandomCrop(28),
                                transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

# define network
net = IdentityResNet(nblk_stage1=4, nblk_stage2=5,
                     nblk_stage3=6, nblk_stage4=3)
```

![result2](./result2.png)

* æœ¬æ¥æƒ³è¦ç»§ç»­è°ƒæ•´å‚æ•°æé«˜å‡†ç¡®ç‡ï¼Œä½†æ˜¯ç”µè„‘å¤ªæ…¢äº†å°±åˆ°æ­¤ä¸ºæ­¢å§ã€‚

  I wanted continue to adjust the parameters to improve the accuracy, but my computer is so slow. Let's stop here.



## ğŸˆ æœ€åè¯´ä¸‹æ„Ÿæƒ³
ç”¨pytorchå†™ç½‘ç»œçœŸçš„æ¯”ç”¨numpyå¿«è€Œä¸”ç®€å•å¤šäº†ï¼Œå½“ç”¨30è¡Œä»£ç å®Œæˆä¹‹å‰500è¡Œç”¨numpyå®Œæˆçš„ç½‘ç»œæ—¶çªç„¶è§‰å¾—ç©ºè™šã€‚  
ä½†æ˜¯ä¸å¾—ä¸æ‰¿è®¤ï¼Œç”¨numpyè‡ªå·±å†™forwardå’Œbackpropå‡½æ•°çš„ç»å†è®©æˆ‘å¯¹æ•´ä¸ªç½‘ç»œçš„å°åˆ°å¤§çš„ç†è§£é€å½»äº†å¾ˆå¤šå¾ˆå¤šï¼Œè¿™åœ¨å†™è¿™ä¸ªç¨‹åºçš„æ—¶å€™ä½“ç°å¾—å¾ˆæ˜æ˜¾ï¼šç†Ÿæ‚‰pytorchè¯­æ³•å’Œå†™æ³•ç„¶åå†™å®Œè¿™ä¸ªç¨‹åºåªèŠ±äº†ä¸€æ—©ä¸Šæ—¶é—´ã€‚